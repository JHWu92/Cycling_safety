{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # coding=utf-8\n",
    "# import geopandas as gp\n",
    "\n",
    "\n",
    "# def fs_api():\n",
    "#     import foursquare\n",
    "#     clients_id_secret = [\n",
    "#         ('B5UXLIK21H3XVVIIKBYVG55XXOAVF50OAEFYT5KNWEZ0AJFS', 'AZGHYGMVF3CPO0VUWQWIFP4DYBEIPUOLCT31SUKVTA3FOQRP'),\n",
    "#         ('VLX3BBUP4VTKT5BP53CBWMTKUWGVGBE34O52S4ULNWAAJURO', '2534VD02WWGCJCILTTRJXXEOPLDTXDVREKXAKGX515HJV3H0'),\n",
    "#         ('VJR0HIRSW5AEWJL1U0YVP2CJNNY1DOMEBRBM3XD15MW55LQZ', 'MM55NWKDFC51M1PU2I3GNXDJQ0NNIDKNVBRNZJSW4COLBQIR'),\n",
    "#         ('CWCA2GY2YJKS4GTCBU4V3KI0KH2KMDVZXVJVKFS5C3VPXGCV', 'NLMSW00OFS2FZDYIEA5ZPM4RH35ZAHHFGQSTTC3BYGGX0OIS'),\n",
    "#         ('GOOWLBFKGWVYJA5E4ES5MUQCF5B2NWITHFNCCVUOLIIN3ZF3', 'UUZ32DS3U5CC22XJ5LIO3RVVMRWL4NFYOM2V3SZ0H1ETWKSC'),\n",
    "#         ('FJLWGSADBT2R1ELM0W14CIHSOSDZ0ZVGGKJOV5CUEC3JSUKM', '0SA5RHLJ5LKRPPPAKQMLJVBB0HCWTQJ2LJD5OPO4LCO3H00L'),\n",
    "#         ('QUKQ3QQUXVAYNJOEYNOJIKLGGFPUTOQ2PWS4PNYJUTVY2UKB', 'BLCCAQAZYXFVLELFDYKJT4EOFLI3WGW4YKMDOIQ2XPFE3J3C'),\n",
    "#         ('I5QIF0SFJCRMAVBSBV3KEZSCQ02MLQZPJ2JPKIG2UFREDUXL', 'GQDNDG03NP4IXXM0QSIJUL3H3KMX0B2OWRNJRVQX3LH3FFOJ'),\n",
    "#         ('NRAQWNRMKH4W1BP3SQXTLJEKCQKXYOH1G0WPEBPFHVKEGZTM', 'BU2ST3EPY3MSUMKU1XLNTVV00XYBFDWCNWIVJNCWQ502OF11'),\n",
    "#     ]\n",
    "\n",
    "#     clients = [foursquare.Foursquare(client_id=client_id, client_secret=client_secret) for client_id, client_secret in\n",
    "#                clients_id_secret]\n",
    "#     return clients\n",
    "\n",
    "# from shapely.geometry import box\n",
    "# def raw_venues_in_city(city_path,frsq_venues_raw_path):\n",
    "#     from src.geom_helper import grid_area\n",
    "#     import time\n",
    "#     clients = fs_api()\n",
    "#     city_poly_gpdf = gp.read_file(city_path)\n",
    "#     city_poly = city_poly_gpdf.geometry.values[0]\n",
    "#     w, s, e, n = city_poly.buffer(0.001).bounds  # buffer a little to handle FS inaccuracy\n",
    "#     grids = grid_area(w, s, e, n, ngrid=100)\n",
    "# #     gpdf = gp.GeoDataFrame([city_poly]+[box(w,s,e,n) for w,s,e,n in grids], columns=['geometry'])\n",
    "#     request_cnt = 0\n",
    "#     data_cach = []\n",
    "#     while len(grids)>0:\n",
    "#         w, s, e, n = grids.pop()\n",
    "#         bbox = box(w, s, e, n)\n",
    "#         if bbox.intersects(city_poly):\n",
    "#             client = clients[request_cnt%len(clients)]\n",
    "#             search = client.venues.search(params={'intent': 'browse', 'sw':'{},{}'.format(s,w), 'ne':'{},{}'.format(n,e), 'limit':50})\n",
    "#             time.sleep(0.02)\n",
    "#             request_cnt += 1\n",
    "#             len_venues = search['venues'].__len__()\n",
    "#             data_cach.append('{}\\t{}\\t{}'.format((w,s,e,n),len_venues, search))\n",
    "#             if len_venues>=50:\n",
    "#                 new_grids = grid_area(w,s,e,n)\n",
    "#                 grids.extend(new_grids)\n",
    "#             if request_cnt%2000==0:\n",
    "#                 output_file = frsq_venues_raw_path+'{}.txt'.format(request_cnt)\n",
    "#                 with open(output_file,'w') as f:\n",
    "#                     print 'writing raw frsq venues: ' + output_file\n",
    "#                     f.write('\\n'.join(data_cach))\n",
    "#                 data_cach = []\n",
    "#     if len(data_cach)>0:\n",
    "#         output_file = frsq_venues_raw_path+'{}.txt'.format(request_cnt)\n",
    "#         with open(output_file,'w') as f:\n",
    "#             print 'writing raw frsq venues:  '+output_file\n",
    "#             f.write('\\n'.join(data_cach))\n",
    "#         data_cach = []\n",
    "\n",
    "# #     return gpdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def show_grids_used(city_path, frsq_venues_raw_path):\n",
    "#     import glob\n",
    "#     city_poly_gpdf = gp.read_file(city_path)\n",
    "#     for fn in glob.glob(frsq_venues_raw_path+'*.txt'):\n",
    "#         with open(fn) as f:\n",
    "#             swne_polys = [box(*eval(line.split('\\t')[0])) for line in f]\n",
    "#         gpdf = gp.GeoDataFrame(swne_polys,columns=['geometry'])\n",
    "#         city_poly_gpdf = city_poly_gpdf.append(gpdf,ignore_index=True)\n",
    "#     print '# grids used:', city_poly_gpdf.shape[0]-1\n",
    "\n",
    "#     ax = city_poly_gpdf.plot(figsize=(45,45))\n",
    "#     fig = ax.get_figure()\n",
    "#     fig.savefig(frsq_venues_raw_path+u'show_grids_used.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def frsq_venues_in_city_geojson(city_path, frsq_venues_raw_path, frsq_venues_in_city_path):\n",
    "#     from pandas.io.json import json_normalize\n",
    "#     import shapely.geometry as shpgeo\n",
    "#     all_venues = []\n",
    "#     for fn in glob.glob(frsq_venues_raw_path+'*.txt'):\n",
    "#         with open(fn) as f:\n",
    "#             for line in f:\n",
    "#                 wsen, vcnt, data = line.split('\\t')\n",
    "#                 data = eval(data)\n",
    "#                 venues = data['venues']\n",
    "#                 all_venues.extend(venues)\n",
    "\n",
    "#     df_venues = json_normalize(all_venues) \n",
    "#     df_venues['categories.name'] = df_venues.categories.apply(lambda x: x[0]['name'] if x else '')\n",
    "#     df_venues['categories.id'] = df_venues.categories.apply(lambda x: x[0]['id'] if x else '')\n",
    "#     df_venues['geometry'] = df_venues.apply(lambda x: shpgeo.Point(x['location.lng'], x['location.lat']), axis=1)\n",
    "#     columns = ['id', 'geometry', 'name', 'stats.checkinsCount', 'stats.tipCount', 'stats.usersCount','categories.name']\n",
    "#     df_no_dup = df_venues[columns].drop_duplicates('id').copy()\n",
    "#     df_no_dup.columns = ['id', 'geometry', 'name', 'checkins', 'tips', 'users','category']\n",
    "#     df_no_dup.shape\n",
    "\n",
    "\n",
    "#     city_poly_gpdf = gp.read_file(city_path)\n",
    "#     city_poly = city_poly_gpdf.geometry.values[0]\n",
    "#     print '# venues in/not in city'\n",
    "#     print df_no_dup.geometry.apply(lambda x: x.intersects(city_poly)).value_counts()\n",
    "#     df_no_dup_in_city = df_no_dup[df_no_dup.geometry.apply(lambda x: x.intersects(city_poly))].copy()\n",
    "\n",
    "#     with open(frsq_venues_in_city_path, 'w') as f:\n",
    "#         f.write(gp.GeoDataFrame(df_no_dup_in_city).to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# venues in city= 30162\n",
      "# venues near segments= 18170\n",
      "wrote frsq_near_segments: data/frsq_venues_dc_near_segments_dc_opendc.geojson\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def frsq_near_segments(frsq_venues_in_city_path, city_segments_path, bfr_crs, bfr_func, init_crs=4326):\n",
    "#     from src.geom_helper import objs_near_segs\n",
    "#     import os\n",
    "\n",
    "#     frsq_venues_in_city = gp.read_file(frsq_venues_in_city_path)\n",
    "#     city_segments = gp.read_file(city_segments_path)\n",
    "#     frsq_venues_near_segments = objs_near_segs(frsq_venues_in_city, city_segments, bfr_func, bfr_crs, output='objs')\n",
    "#     print '# venues in city=',frsq_venues_in_city.shape[0]\n",
    "#     print '# venues near segments=', frsq_venues_near_segments.shape[0]\n",
    "    \n",
    "#     fn_venues, ext = os.path.splitext(frsq_venues_in_city_path)\n",
    "#     fn_segs, ext = os.path.splitext(os.path.basename(city_segments_path))\n",
    "#     new_path = '{fnv}_near_{fns}{ext}'.format(fnv=fn_venues, fns=fn_segs, ext=ext)\n",
    "#     with open(new_path, 'w') as f:\n",
    "#         f.write(frsq_venues_near_segments.to_json())\n",
    "#     print 'wrote frsq_near_segments:', new_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def parse_frsq_taxonomy(frsq_taxonomy_json_path, frsq_taxonomy_csv_path, frsq_taxonomy_tree_path):\n",
    "#     import json\n",
    "#     import pandas as pd\n",
    "\n",
    "#     with open(frsq_taxonomy_json_path) as f:\n",
    "#         js = json.load(f)\n",
    "#         categories = js['response']['categories']\n",
    "    \n",
    "#     # parse children categories recursively\n",
    "#     def parse_categories(categories,parent_id,level):\n",
    "#         result = []\n",
    "#         for order,cate in enumerate(categories):\n",
    "#             cid, pluralName, shortName, name, icon = cate['id'], cate['pluralName'], cate['shortName'], cate['name'], cate['icon']        \n",
    "#             sub_result=[]\n",
    "#             if 'categories' in cate and cate['categories']:\n",
    "#                 sub_result = parse_categories(cate['categories'], cid, level+1)\n",
    "#             result.append([parent_id, cid, pluralName.strip(), shortName.strip(), name.strip(), icon, level,order])\n",
    "#             result.extend(sub_result)\n",
    "#     #         break\n",
    "#         return result\n",
    "\n",
    "#     df = pd.DataFrame(parse_categories(categories,'root',1))\n",
    "#     df.columns = ['parent_id', 'cid', 'pluralName', 'shortName', 'name', 'icon', 'level','order']\n",
    "    \n",
    "#     print 'parsed FourSquare taxonomy'\n",
    "#     for i in range(1,7):\n",
    "#         sub_df = df.query('level==%d' %i)\n",
    "#         print 'level=', i, '# categories', sub_df.shape[0], 'parent categories', sub_df.parent_id.value_counts().shape[0]\n",
    "\n",
    "#     df.drop('icon', axis=1).to_csv(frsq_taxonomy_csv_path, encoding='utf-8')\n",
    "\n",
    "#     with open(frsq_taxonomy_tree_path,'w') as f:\n",
    "#         f.write('\\n'.join(df.apply(lambda x:'{}{}'.format('\\t'*x.level, x['name'].encode('utf-8')), axis=1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.frsq_helper import raw_venues_in_city, show_grids_used, frsq_venues_in_city_geojson, frsq_near_segments, parse_frsq_taxonomy\n",
    "from src.constants import fn_city_poly_dc, dir_frsq_raw_venues_dc, fn_frsq_venues_dc,fn_segments_dc, fn_frsq_taxonomy_json, fn_frsq_taxonomy_csv, fn_frsq_taxonomy_tree\n",
    "data_dir=u'data/'\n",
    "city_path = data_dir + fn_city_poly_dc\n",
    "frsq_venues_raw_path = data_dir + dir_frsq_raw_venues_dc\n",
    "frsq_venues_in_city_path = data_dir+fn_frsq_venues_dc\n",
    "city_segments_path = data_dir + fn_segments_dc\n",
    "frsq_taxonomy_json_path = data_dir + fn_frsq_taxonomy_json\n",
    "frsq_taxonomy_csv_path = data_dir + fn_frsq_taxonomy_csv\n",
    "frsq_taxonomy_tree_path = data_dir + fn_frsq_taxonomy_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing raw frsq venues: data/frsq_raw_venues/dc/2000.txt\n",
      "writing raw frsq venues: data/frsq_raw_venues/dc/4000.txt\n",
      "writing raw frsq venues: data/frsq_raw_venues/dc/6000.txt\n",
      "writing raw frsq venues: data/frsq_raw_venues/dc/8000.txt\n",
      "writing raw frsq venues: data/frsq_raw_venues/dc/10000.txt\n",
      "writing raw frsq venues: data/frsq_raw_venues/dc/12000.txt\n",
      "writing raw frsq venues: data/frsq_raw_venues/dc/14000.txt\n",
      "writing raw frsq venues: data/frsq_raw_venues/dc/16000.txt\n",
      "writing raw frsq venues: data/frsq_raw_venues/dc/18000.txt\n",
      "writing raw frsq venues:  data/frsq_raw_venues/dc/18078.txt\n"
     ]
    }
   ],
   "source": [
    "raw_venues_in_city(city_path, frsq_venues_raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# grids used: 18078\n"
     ]
    }
   ],
   "source": [
    "show_grids_used(city_path, frsq_venues_raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# venues in/not in city\n",
      "True     30151\n",
      "False      535\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "frsq_venues_in_city_geojson(city_path, frsq_venues_raw_path, frsq_venues_in_city_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# venues in city= 30151\n",
      "# venues near segments= 18157\n",
      "wrote frsq_near_segments: data/frsq_venues_dc_near_segments_dc_opendc.geojson\n"
     ]
    }
   ],
   "source": [
    "from src.geom_helper import bfr_20m\n",
    "frsq_near_segments(frsq_venues_in_city_path, city_segments_path, 3559, bfr_20m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed FourSquare taxonomy\n",
      "level= 1 # categories 10 parent categories 1\n",
      "level= 2 # categories 437 parent categories 10\n",
      "level= 3 # categories 345 parent categories 49\n",
      "level= 4 # categories 81 parent categories 8\n",
      "level= 5 # categories 13 parent categories 1\n",
      "level= 6 # categories 0 parent categories 0\n"
     ]
    }
   ],
   "source": [
    "parse_frsq_taxonomy(frsq_taxonomy_json_path, frsq_taxonomy_csv_path, frsq_taxonomy_tree_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
