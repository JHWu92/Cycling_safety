{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point,LineString\n",
    "from IPython.display import display\n",
    "from pygeocoder import Geocoder\n",
    "import numpy as np,mapbox as mp\n",
    "import googlemaps,csv,math,os,re\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from operator import itemgetter\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import pickle,multiprocessing as mproc, seaborn as sns\n",
    "from scipy.sparse import csr_matrix,vstack\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CLASS</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FNODE_</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LENGTH</th>\n",
       "      <td>449.863</td>\n",
       "      <td>540.083</td>\n",
       "      <td>446.104</td>\n",
       "      <td>447.261</td>\n",
       "      <td>148.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPOLY_</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_F_ADD</th>\n",
       "      <td>1500</td>\n",
       "      <td>400</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_HUNDRED</th>\n",
       "      <td>1500</td>\n",
       "      <td>400</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L_T_ADD</th>\n",
       "      <td>1598</td>\n",
       "      <td>498</td>\n",
       "      <td>1698</td>\n",
       "      <td>1698</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MULTI_REP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEWSEGDATE</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONEWAY</th>\n",
       "      <td>FT</td>\n",
       "      <td>TF</td>\n",
       "      <td>FT</td>\n",
       "      <td>TF</td>\n",
       "      <td>TF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE_DIR</th>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RESPONSIBL</th>\n",
       "      <td>FAM</td>\n",
       "      <td>FAM</td>\n",
       "      <td>FAM</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPOLY_</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_F_ADD</th>\n",
       "      <td>1501</td>\n",
       "      <td>401</td>\n",
       "      <td>1601</td>\n",
       "      <td>1601</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_HUNDRED</th>\n",
       "      <td>1500</td>\n",
       "      <td>400</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_T_ADD</th>\n",
       "      <td>1599</td>\n",
       "      <td>499</td>\n",
       "      <td>1699</td>\n",
       "      <td>1699</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEG_ID</th>\n",
       "      <td>420708</td>\n",
       "      <td>422065</td>\n",
       "      <td>420702</td>\n",
       "      <td>420732</td>\n",
       "      <td>420718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHAPE_LEN</th>\n",
       "      <td>449.863</td>\n",
       "      <td>540.083</td>\n",
       "      <td>446.104</td>\n",
       "      <td>447.261</td>\n",
       "      <td>148.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STCL2_</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STCL2_ID</th>\n",
       "      <td>85205</td>\n",
       "      <td>86540</td>\n",
       "      <td>85199</td>\n",
       "      <td>85229</td>\n",
       "      <td>85215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STNAME</th>\n",
       "      <td>CALLOWHILL ST</td>\n",
       "      <td>N 15TH ST</td>\n",
       "      <td>CALLOWHILL ST</td>\n",
       "      <td>CARLTON ST</td>\n",
       "      <td>N 17TH ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STREETLABE</th>\n",
       "      <td>CALLOWHILL ST</td>\n",
       "      <td>N 15TH ST</td>\n",
       "      <td>CALLOWHILL ST</td>\n",
       "      <td>CARLTON ST</td>\n",
       "      <td>N 17TH ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST_CODE</th>\n",
       "      <td>20880</td>\n",
       "      <td>88070</td>\n",
       "      <td>20880</td>\n",
       "      <td>21440</td>\n",
       "      <td>88110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST_NAME</th>\n",
       "      <td>CALLOWHILL</td>\n",
       "      <td>15TH</td>\n",
       "      <td>CALLOWHILL</td>\n",
       "      <td>CARLTON</td>\n",
       "      <td>17TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST_TYPE</th>\n",
       "      <td>ST</td>\n",
       "      <td>ST</td>\n",
       "      <td>ST</td>\n",
       "      <td>ST</td>\n",
       "      <td>ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUF_DIR</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TNODE_</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPDATE_</th>\n",
       "      <td>1997-02-10</td>\n",
       "      <td>1997-02-10</td>\n",
       "      <td>1997-02-10</td>\n",
       "      <td>1997-02-10</td>\n",
       "      <td>1997-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIP_LEFT</th>\n",
       "      <td>19130</td>\n",
       "      <td>19130</td>\n",
       "      <td>19130</td>\n",
       "      <td>19103</td>\n",
       "      <td>19103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZIP_RIGHT</th>\n",
       "      <td>19130</td>\n",
       "      <td>19130</td>\n",
       "      <td>19130</td>\n",
       "      <td>19103</td>\n",
       "      <td>19103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geometry</th>\n",
       "      <td>LINESTRING (-75.16371257852462 39.959816984389...</td>\n",
       "      <td>LINESTRING (-75.16371257852462 39.959816984389...</td>\n",
       "      <td>LINESTRING (-75.16529687686355 39.960013687935...</td>\n",
       "      <td>LINESTRING (-75.16537539004391 39.959601782423...</td>\n",
       "      <td>LINESTRING (-75.16694872703492 39.959805718080...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0  \\\n",
       "CLASS                                                       3   \n",
       "FNODE_                                                      2   \n",
       "LENGTH                                                449.863   \n",
       "LPOLY_                                                      0   \n",
       "L_F_ADD                                                  1500   \n",
       "L_HUNDRED                                                1500   \n",
       "L_T_ADD                                                  1598   \n",
       "MULTI_REP                                                   0   \n",
       "NEWSEGDATE                                               None   \n",
       "ONEWAY                                                     FT   \n",
       "PRE_DIR                                                  None   \n",
       "RESPONSIBL                                                FAM   \n",
       "RPOLY_                                                      0   \n",
       "R_F_ADD                                                  1501   \n",
       "R_HUNDRED                                                1500   \n",
       "R_T_ADD                                                  1599   \n",
       "SEG_ID                                                 420708   \n",
       "SHAPE_LEN                                             449.863   \n",
       "STCL2_                                                      1   \n",
       "STCL2_ID                                                85205   \n",
       "STNAME                                          CALLOWHILL ST   \n",
       "STREETLABE                                      CALLOWHILL ST   \n",
       "ST_CODE                                                 20880   \n",
       "ST_NAME                                            CALLOWHILL   \n",
       "ST_TYPE                                                    ST   \n",
       "SUF_DIR                                                  None   \n",
       "TNODE_                                                      1   \n",
       "UPDATE_                                            1997-02-10   \n",
       "ZIP_LEFT                                                19130   \n",
       "ZIP_RIGHT                                               19130   \n",
       "geometry    LINESTRING (-75.16371257852462 39.959816984389...   \n",
       "\n",
       "                                                            1  \\\n",
       "CLASS                                                       3   \n",
       "FNODE_                                                      2   \n",
       "LENGTH                                                540.083   \n",
       "LPOLY_                                                      0   \n",
       "L_F_ADD                                                   400   \n",
       "L_HUNDRED                                                 400   \n",
       "L_T_ADD                                                   498   \n",
       "MULTI_REP                                                   0   \n",
       "NEWSEGDATE                                               None   \n",
       "ONEWAY                                                     TF   \n",
       "PRE_DIR                                                     N   \n",
       "RESPONSIBL                                                FAM   \n",
       "RPOLY_                                                      0   \n",
       "R_F_ADD                                                   401   \n",
       "R_HUNDRED                                                 400   \n",
       "R_T_ADD                                                   499   \n",
       "SEG_ID                                                 422065   \n",
       "SHAPE_LEN                                             540.083   \n",
       "STCL2_                                                      2   \n",
       "STCL2_ID                                                86540   \n",
       "STNAME                                              N 15TH ST   \n",
       "STREETLABE                                          N 15TH ST   \n",
       "ST_CODE                                                 88070   \n",
       "ST_NAME                                                  15TH   \n",
       "ST_TYPE                                                    ST   \n",
       "SUF_DIR                                                  None   \n",
       "TNODE_                                                      3   \n",
       "UPDATE_                                            1997-02-10   \n",
       "ZIP_LEFT                                                19130   \n",
       "ZIP_RIGHT                                               19130   \n",
       "geometry    LINESTRING (-75.16371257852462 39.959816984389...   \n",
       "\n",
       "                                                            2  \\\n",
       "CLASS                                                       3   \n",
       "FNODE_                                                      1   \n",
       "LENGTH                                                446.104   \n",
       "LPOLY_                                                      0   \n",
       "L_F_ADD                                                  1600   \n",
       "L_HUNDRED                                                1600   \n",
       "L_T_ADD                                                  1698   \n",
       "MULTI_REP                                                   0   \n",
       "NEWSEGDATE                                               None   \n",
       "ONEWAY                                                     FT   \n",
       "PRE_DIR                                                  None   \n",
       "RESPONSIBL                                                FAM   \n",
       "RPOLY_                                                      0   \n",
       "R_F_ADD                                                  1601   \n",
       "R_HUNDRED                                                1600   \n",
       "R_T_ADD                                                  1699   \n",
       "SEG_ID                                                 420702   \n",
       "SHAPE_LEN                                             446.104   \n",
       "STCL2_                                                      3   \n",
       "STCL2_ID                                                85199   \n",
       "STNAME                                          CALLOWHILL ST   \n",
       "STREETLABE                                      CALLOWHILL ST   \n",
       "ST_CODE                                                 20880   \n",
       "ST_NAME                                            CALLOWHILL   \n",
       "ST_TYPE                                                    ST   \n",
       "SUF_DIR                                                  None   \n",
       "TNODE_                                                      4   \n",
       "UPDATE_                                            1997-02-10   \n",
       "ZIP_LEFT                                                19130   \n",
       "ZIP_RIGHT                                               19130   \n",
       "geometry    LINESTRING (-75.16529687686355 39.960013687935...   \n",
       "\n",
       "                                                            3  \\\n",
       "CLASS                                                       5   \n",
       "FNODE_                                                      6   \n",
       "LENGTH                                                447.261   \n",
       "LPOLY_                                                      0   \n",
       "L_F_ADD                                                  1600   \n",
       "L_HUNDRED                                                1600   \n",
       "L_T_ADD                                                  1698   \n",
       "MULTI_REP                                                   0   \n",
       "NEWSEGDATE                                               None   \n",
       "ONEWAY                                                     TF   \n",
       "PRE_DIR                                                  None   \n",
       "RESPONSIBL                                               None   \n",
       "RPOLY_                                                      0   \n",
       "R_F_ADD                                                  1601   \n",
       "R_HUNDRED                                                1600   \n",
       "R_T_ADD                                                  1699   \n",
       "SEG_ID                                                 420732   \n",
       "SHAPE_LEN                                             447.261   \n",
       "STCL2_                                                      4   \n",
       "STCL2_ID                                                85229   \n",
       "STNAME                                             CARLTON ST   \n",
       "STREETLABE                                         CARLTON ST   \n",
       "ST_CODE                                                 21440   \n",
       "ST_NAME                                               CARLTON   \n",
       "ST_TYPE                                                    ST   \n",
       "SUF_DIR                                                  None   \n",
       "TNODE_                                                      5   \n",
       "UPDATE_                                            1997-02-10   \n",
       "ZIP_LEFT                                                19103   \n",
       "ZIP_RIGHT                                               19103   \n",
       "geometry    LINESTRING (-75.16537539004391 39.959601782423...   \n",
       "\n",
       "                                                            4  \n",
       "CLASS                                                       4  \n",
       "FNODE_                                                      5  \n",
       "LENGTH                                                148.216  \n",
       "LPOLY_                                                      0  \n",
       "L_F_ADD                                                   350  \n",
       "L_HUNDRED                                                 300  \n",
       "L_T_ADD                                                   398  \n",
       "MULTI_REP                                                   0  \n",
       "NEWSEGDATE                                               None  \n",
       "ONEWAY                                                     TF  \n",
       "PRE_DIR                                                     N  \n",
       "RESPONSIBL                                               None  \n",
       "RPOLY_                                                      0  \n",
       "R_F_ADD                                                   351  \n",
       "R_HUNDRED                                                 300  \n",
       "R_T_ADD                                                   399  \n",
       "SEG_ID                                                 420718  \n",
       "SHAPE_LEN                                             148.216  \n",
       "STCL2_                                                      5  \n",
       "STCL2_ID                                                85215  \n",
       "STNAME                                              N 17TH ST  \n",
       "STREETLABE                                          N 17TH ST  \n",
       "ST_CODE                                                 88110  \n",
       "ST_NAME                                                  17TH  \n",
       "ST_TYPE                                                    ST  \n",
       "SUF_DIR                                                  None  \n",
       "TNODE_                                                      4  \n",
       "UPDATE_                                            1997-06-27  \n",
       "ZIP_LEFT                                                19103  \n",
       "ZIP_RIGHT                                               19103  \n",
       "geometry    LINESTRING (-75.16694872703492 39.959805718080...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ph_str_gpd = gpd.read_file('../phillydata/Street_Centerline_qgis3.geojson')\n",
    "# ph_str_bfr_gpd = ph_str_gpd[['STCL2_ID','SEG_ID','geometry']].copy()\n",
    "# ph_str_bfr_gpd.geometry = ph_str_bfr_gpd.buffer(0.0001)\n",
    "ph_str_gpd.head().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purp = pd.read_pickle('Route_Purpose.pkl')\n",
    "purp['Start'] = pd.DatetimeIndex(purp.Start)\n",
    "purp['Stop'] = pd.DatetimeIndex(purp.Stop)\n",
    "\n",
    "o1 = np.loadtxt('Output1.txt',dtype='int')\n",
    "o2 = open('Output2.txt').readlines()\n",
    "o2 = np.array([int(re.findall('[0-9]+',t)[0]) for t in o2])\n",
    "indices = np.sort(np.append(o1,o2))\n",
    "print(\"Routes outside \"+str(len(o1)))\n",
    "print(\"Routes partially outside \"+str(len(o2)))\n",
    "print(\"Routes completely inside \"+str(len(purp)-len(indices)))\n",
    "new = purp.ix[set(range(len(purp)))-set(indices)]\n",
    "trip_len = np.array([len(row.geometry.coords) for idx,row in new.iterrows()])\n",
    "temp = [True if 2<len(row.geometry.coords)<=300 else False for idx,row in new.iterrows()]\n",
    "new = new.ix[temp].reset_index(drop=True)\n",
    "print(\"Routes that are atmost 300 and atleast 3 points long \"+str(len(new)))\n",
    "new.head()\n",
    "# f = open('Data.pkl','wb')\n",
    "# pickle.dump(new, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(new,open('Route_Choice.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purp = gpd.read_file('tripbytrip_rd2_geojson.geojson')\n",
    "purp = purp[purp.geometry.type==\"LineString\"]\n",
    "purp.reset_index(inplace=True,drop=True)\n",
    "\n",
    "temp = [True if 2<len(row.geometry.coords)<=300 else False for idx,row in purp.iterrows()]\n",
    "purp = purp.ix[temp].reset_index(drop=True)\n",
    "purp = purp.ix[purp[['Purpose','UserId','Start']].drop_duplicates().index].reset_index(drop=True)\n",
    "temp = purp.geometry.apply(lambda x: x in new.geometry)\n",
    "purp = purp[temp].reset_index(drop=True)\n",
    "\n",
    "temp1 = [list(temp.coords) for temp in purp.geometry]\n",
    "temp2 = [list(temp.coords) for temp in new.geometry]\n",
    "\n",
    "temp = [temp2.index(t) for t in temp1]\n",
    "\n",
    "purp['Start'] = pd.to_datetime(purp.Start)\n",
    "purp['seg'] = temp\n",
    "\n",
    "purp.to_pickle('Final_Data.pkl')\n",
    "print(purp.shape)\n",
    "purp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7629, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Purpose</th>\n",
       "      <td>Commute</td>\n",
       "      <td>Commute</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>Commute</td>\n",
       "      <td>Commute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Start</th>\n",
       "      <td>2014-09-18 16:54:57</td>\n",
       "      <td>2014-09-19 08:24:54</td>\n",
       "      <td>2014-09-19 16:18:02</td>\n",
       "      <td>2014-09-22 08:12:23</td>\n",
       "      <td>2014-09-22 16:52:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stop</th>\n",
       "      <td>2014-09-18T17:21:29</td>\n",
       "      <td>2014-09-19T08:54:03</td>\n",
       "      <td>2014-09-19T16:36:25</td>\n",
       "      <td>2014-09-22T08:34:15</td>\n",
       "      <td>2014-09-22T17:23:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TripID</th>\n",
       "      <td>10020</td>\n",
       "      <td>10082</td>\n",
       "      <td>10128</td>\n",
       "      <td>10228</td>\n",
       "      <td>10265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserId</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>35 - 44</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>35 - 44</td>\n",
       "      <td>35 - 44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cycling_fr</th>\n",
       "      <td>Daily</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Daily</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geometry</th>\n",
       "      <td>LINESTRING (-75.18906357192628 39.957607633485...</td>\n",
       "      <td>LINESTRING (-75.14535405814325 39.963978383195...</td>\n",
       "      <td>LINESTRING (-75.19162367019618 39.955083562056...</td>\n",
       "      <td>LINESTRING (-75.14779781921396 39.963528080956...</td>\n",
       "      <td>LINESTRING (-75.18931917633887 39.956421811717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>&lt; $20,000</td>\n",
       "      <td>&lt; $20,000</td>\n",
       "      <td>&lt; $20,000</td>\n",
       "      <td>&lt; $20,000</td>\n",
       "      <td>&lt; $20,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rider_hist</th>\n",
       "      <td>Since childhood</td>\n",
       "      <td>Since childhood</td>\n",
       "      <td>Since childhood</td>\n",
       "      <td>Since childhood</td>\n",
       "      <td>Since childhood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rider_type</th>\n",
       "      <td>Strong &amp; Fearless</td>\n",
       "      <td>Strong &amp; Fearless</td>\n",
       "      <td>Strong &amp; Fearless</td>\n",
       "      <td>Strong &amp; Fearless</td>\n",
       "      <td>Strong &amp; Fearless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg</th>\n",
       "      <td>587</td>\n",
       "      <td>873</td>\n",
       "      <td>4711</td>\n",
       "      <td>1686</td>\n",
       "      <td>1685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0  \\\n",
       "Purpose                                               Commute   \n",
       "Start                                     2014-09-18 16:54:57   \n",
       "Stop                                      2014-09-18T17:21:29   \n",
       "TripID                                                  10020   \n",
       "UserId                                                      1   \n",
       "age                                                   35 - 44   \n",
       "cycling_fr                                              Daily   \n",
       "ethnicity                                               White   \n",
       "gender                                                   Male   \n",
       "geometry    LINESTRING (-75.18906357192628 39.957607633485...   \n",
       "income                                              < $20,000   \n",
       "rider_hist                                    Since childhood   \n",
       "rider_type                                  Strong & Fearless   \n",
       "seg                                                       587   \n",
       "\n",
       "                                                            1  \\\n",
       "Purpose                                               Commute   \n",
       "Start                                     2014-09-19 08:24:54   \n",
       "Stop                                      2014-09-19T08:54:03   \n",
       "TripID                                                  10082   \n",
       "UserId                                                      1   \n",
       "age                                                   35 - 44   \n",
       "cycling_fr                                              Daily   \n",
       "ethnicity                                               White   \n",
       "gender                                                   Male   \n",
       "geometry    LINESTRING (-75.14535405814325 39.963978383195...   \n",
       "income                                              < $20,000   \n",
       "rider_hist                                    Since childhood   \n",
       "rider_type                                  Strong & Fearless   \n",
       "seg                                                       873   \n",
       "\n",
       "                                                            2  \\\n",
       "Purpose                                              Shopping   \n",
       "Start                                     2014-09-19 16:18:02   \n",
       "Stop                                      2014-09-19T16:36:25   \n",
       "TripID                                                  10128   \n",
       "UserId                                                      1   \n",
       "age                                                   35 - 44   \n",
       "cycling_fr                                              Daily   \n",
       "ethnicity                                               White   \n",
       "gender                                                   Male   \n",
       "geometry    LINESTRING (-75.19162367019618 39.955083562056...   \n",
       "income                                              < $20,000   \n",
       "rider_hist                                    Since childhood   \n",
       "rider_type                                  Strong & Fearless   \n",
       "seg                                                      4711   \n",
       "\n",
       "                                                            3  \\\n",
       "Purpose                                               Commute   \n",
       "Start                                     2014-09-22 08:12:23   \n",
       "Stop                                      2014-09-22T08:34:15   \n",
       "TripID                                                  10228   \n",
       "UserId                                                      1   \n",
       "age                                                   35 - 44   \n",
       "cycling_fr                                              Daily   \n",
       "ethnicity                                               White   \n",
       "gender                                                   Male   \n",
       "geometry    LINESTRING (-75.14779781921396 39.963528080956...   \n",
       "income                                              < $20,000   \n",
       "rider_hist                                    Since childhood   \n",
       "rider_type                                  Strong & Fearless   \n",
       "seg                                                      1686   \n",
       "\n",
       "                                                            4  \n",
       "Purpose                                               Commute  \n",
       "Start                                     2014-09-22 16:52:26  \n",
       "Stop                                      2014-09-22T17:23:57  \n",
       "TripID                                                  10265  \n",
       "UserId                                                      1  \n",
       "age                                                   35 - 44  \n",
       "cycling_fr                                              Daily  \n",
       "ethnicity                                               White  \n",
       "gender                                                   Male  \n",
       "geometry    LINESTRING (-75.18931917633887 39.956421811717...  \n",
       "income                                              < $20,000  \n",
       "rider_hist                                    Since childhood  \n",
       "rider_type                                  Strong & Fearless  \n",
       "seg                                                      1685  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purp = pickle.load(open('Final_Data.pkl','rb'))\n",
    "print(purp.shape)\n",
    "purp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import geopandas as gp\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    from math import radians, cos, sin, asin, sqrt\n",
    "    # convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    km = 6367 * c\n",
    "    m = km * 1000\n",
    "    return m\n",
    "\n",
    "\n",
    "def ptfromln(pt, ln):\n",
    "    \"\"\"\n",
    "    project pt to ln, compute haversine distance between projected pt and pt\n",
    "    :param pt: shapely.geometry.Point, (lon, lat) point\n",
    "    :param ln: shapely.geometry.LineString, [(lon,lat)] points\n",
    "    :return: distance in meters\n",
    "    \"\"\"\n",
    "    n_pt = ln.interpolate(ln.project(pt))\n",
    "    lon1, lat1 = n_pt.coords[0]\n",
    "    lon2, lat2 = pt.coords[0]\n",
    "    return haversine(lon1, lat1, lon2, lat2)\n",
    "\n",
    "def crs_prepossess(gpdf, init_crs, bfr_crs):\n",
    "    \"\"\"\n",
    "    create a shallow copy of gpdf; check the init crs of gpdf, if None, assign init_crs; change crs of copy to bfr_crs\n",
    "    :param gpdf: geopandas.GeoDataFrame\n",
    "    :param init_crs: init_crs epsg code\n",
    "    :param bfr_crs: target crs epsg code used for buffering\n",
    "    :return: a shallow copy of gpdf in bfr_crs\n",
    "    \"\"\"\n",
    "    gpdf_crs = gpdf.copy()\n",
    "    if gpdf_crs.crs == None:\n",
    "        gpdf_crs.crs = {'init': u'epsg:{}'.format(init_crs)}\n",
    "    return gpdf_crs.to_crs(epsg=bfr_crs)\n",
    "\n",
    "\n",
    "# ########## functions assigning ln(segment) to objs #############\n",
    "def pts2segs(pts, lns, bfr_crs, init_crs=4326, close_jn_dist=10, far_jn_dist=20):\n",
    "    \"\"\"\n",
    "    1. close jn: buffer pts in bfr_crs with close_jn_dist, use sjoin to find segment(s) intersected with buffered pts\n",
    "    2. far jn: for pts without any segment in close jn, buffer them with far_jn_dist and find nearest segment\n",
    "    :param pts: geopandas.GeoDataFrame\n",
    "    :param lns: geopandas.GeoDataFrame\n",
    "    :param bfr_crs: target crs epsg code used for buffering\n",
    "    :param init_crs: init_crs epsg code, default 4326(lat lon)\n",
    "    :param close_jn_dist: close join distance, allowing multiple segments for one point(assumed as intersection)\n",
    "    :param far_jn_dist: far join distance, find the nearest segment for one point\n",
    "    :return: pandas.DataFrame, columns=[pt_index, ln_index]\n",
    "    \"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    index_pt, index_ln = 'index_pt', 'index_ln'\n",
    "\n",
    "    lns_crs = crs_prepossess(lns, init_crs, bfr_crs)\n",
    "    pts_crs = crs_prepossess(pts, init_crs, bfr_crs)\n",
    "\n",
    "    close_jn = pts_crs.copy()\n",
    "    close_jn.geometry = close_jn.buffer(close_jn_dist)\n",
    "    close_jn = gp.tools.sjoin(close_jn, lns_crs)[['index_right']]\n",
    "\n",
    "    close_jn_pts = set(pd.unique(close_jn.index))\n",
    "    far_jn = pts_crs[~pts_crs.index.isin(close_jn_pts)].copy()\n",
    "    \n",
    "    if not far_jn.empty:\n",
    "        far_jn.geometry = far_jn.buffer(far_jn_dist)\n",
    "        far_jn = gp.tools.sjoin(far_jn, lns_crs)[['index_right']]\n",
    "        # calculate haversine distance\n",
    "        far_jn = pd.merge(lns[['geometry']], far_jn, left_index=True, right_on=['index_right'])\n",
    "        far_jn = pd.merge(pts[['geometry']], far_jn, left_index=True, right_index=True)\n",
    "        far_jn['dis'] = far_jn.apply(lambda x: ptfromln(x.geometry_x, x.geometry_y), axis=1)\n",
    "        # keep ln with minimum distance to pt\n",
    "        far_jn = far_jn.groupby(level=0).apply(lambda x: x.iloc[x.dis.values.argmin()][['index_right']])\n",
    "        pts_has_ln = close_jn.append(far_jn).reset_index()\n",
    "    else:\n",
    "        pts_has_ln = close_jn.reset_index()\n",
    "\n",
    "    pts_has_ln.columns = [index_pt, index_ln]\n",
    "\n",
    "    pts_no_ln = pts[~pts.index.isin(pd.unique(pts_has_ln[index_pt]))].copy()\n",
    "    return pts_has_ln, pts_no_ln\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import geopandas as gp\n",
    "    # points are (lon, lat)\n",
    "    from shapely.geometry import Point\n",
    "#     idx = 216\n",
    "#     lonlats = list(new.geometry[idx].coords)\n",
    "# #     lonlats = snap(new.iloc[idx])\n",
    "#     pts = [Point(lonlat) for lonlat in lonlats]\n",
    "#     pts_gpdf = gp.GeoDataFrame(pts, columns=['geometry'])\n",
    "#     # get segment index of segs for each point\n",
    "#     pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "#     # get the STREETSEGID for each point\n",
    "#     pts_segids = pts_segs_idx.merge(ph_str_gpd[['SEG_ID']], left_on=['index_ln'], right_index=True)\n",
    "#     pts_segids.sort_values(by=['index_pt'],inplace=True)\n",
    "#     pts_segids.reset_index(inplace=True,drop=True)\n",
    "#     map_plot(idx,True,list(set(pts_segids.index_ln)),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_plot(idx,False,list(set(pts_segids.index_ln)),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts_segids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POI imputation of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in upoi[t==1].index:\n",
    "    lonlats = list(new.geometry[idx].coords)\n",
    "    #     lonlats = snap(new.iloc[idx])\n",
    "    pts = [Point(lonlat) for lonlat in lonlats]\n",
    "    pts_gpdf = gpd.GeoDataFrame(pts, columns=['geometry'])\n",
    "    # get segment index of segs for each point\n",
    "    pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "    # get the STREETSEGID for each point\n",
    "    pts_segids = pts_segs_idx.merge(ph_str_gpd[['SEG_ID']], left_on=['index_ln'], right_index=True)\n",
    "    pts_segids.sort_values(by=['index_pt'],inplace=True)\n",
    "    pts_segids.reset_index(inplace=True,drop=True)\n",
    "    temp1 = pts_segids['index_ln'].groupby(pts_segids['index_pt']).apply(list)\n",
    "    temp = [set(u)&set(v) for u,v in list(zip(temp1,temp1[1:]))]\n",
    "    if(not upoi.start[idx]):\n",
    "        ans = temp[0]\n",
    "        i = 1\n",
    "        while(not ans):\n",
    "            ans = temp[i]\n",
    "            i = i+1\n",
    "        upoi.start[idx] = ans\n",
    "    else:\n",
    "        ans = temp[-1]\n",
    "        i = len(temp)-2\n",
    "        while(not ans):\n",
    "            ans = temp[i]\n",
    "            i = i - 1\n",
    "        upoi.end[idx] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp1 = pts_segids['index_ln'].groupby(pts_segids['index_pt']).apply(list)\n",
    "temp = [set(u)&set(v) for u,v in list(zip(temp1,temp1[1:]))]\n",
    "\n",
    "for i,val in enumerate(temp):\n",
    "    if(len(val)>1): \n",
    "        left = i-1\n",
    "        right = i+1\n",
    "        if(left<0): left = 0\n",
    "        if(right==len(temp)): right = len(temp)-1\n",
    "        if(not t1):\n",
    "            t2 = temp[right] & val\n",
    "            if(not t2):\n",
    "                print(i)\n",
    "            else:\n",
    "                temp[i] = t2\n",
    "        else: temp[i] = t1 \n",
    "temp\n",
    "# map_plot(idx,False,list(set.union(*temp)),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(segments.segments[146])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map_plot(idx,True,list(set(flat(temp1[6:8]))),False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = new.ix[2279]\n",
    "pts = list(row.geometry.coords)\n",
    "samay = [(row.Start + k*(row.Stop-row.Start)/(len(pts)-1)).strftime('%H:%M:%S') for k in range(len(pts))]\n",
    "\n",
    "rang = list(zip(*pts))\n",
    "rang = [list(temp) for temp in rang]\n",
    "df = list(zip(samay,rang[0],rang[1]))\n",
    "data = pd.DataFrame(df,columns=['time','longitude','latitude'])\n",
    "data = data[6:8]\n",
    "service = mp.MapMatcher()\n",
    "gps = snap_to_road(service,data)\n",
    "\n",
    "gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = set.union(*segments.segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upoi[t==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_writer(lonlats,'Trip1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(new.geometry[1768].coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new.geometry[1768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments.segments[1768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lonlats1 = list(new.geometry[430].coords)\n",
    "file_writer(lonlats1,'Trip1.csv')\n",
    "lonlats2 = snap(new.iloc[430])\n",
    "file_writer(lonlats2,'Trip2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import mapbox as mp\n",
    "from snap_to_road import *\n",
    "\n",
    "def snap(row):\n",
    "\n",
    "    pts = list(row.geometry.coords)\n",
    "    samay = [(row.Start + k*(row.Stop-row.Start)/(len(pts)-1)).strftime('%H:%M:%S') for k in range(len(pts))]\n",
    "\n",
    "    rang = list(zip(*pts))\n",
    "    rang = [list(temp) for temp in rang]\n",
    "    df = list(zip(samay,rang[0],rang[1]))\n",
    "    data = pd.DataFrame(df,columns=['time','longitude','latitude'])\n",
    "\n",
    "    \n",
    "    service = mp.MapMatcher()\n",
    "    gps = snap_to_road(service,data)\n",
    "\n",
    "    return gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = list()\n",
    "new = pd.read_pickle('Data.pkl')\n",
    "for idx,row in new.iterrows():\n",
    "    if(idx==5): break\n",
    "    lonlats = snap(row)\n",
    "    pts = [Point(lonlat) for lonlat in lonlats]\n",
    "    pts_gpdf = gpd.GeoDataFrame(pts, columns=['geometry'])\n",
    "\n",
    "    # get segment index of segs for each point\n",
    "    pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "\n",
    "    # get the STREETSEGID for each point\n",
    "    pts_segids = pts_segs_idx.merge(ph_str_gpd[['SEG_ID']], left_on=['index_ln'], right_index=True)\n",
    "    pts_segids.sort_values(by=['index_pt'],inplace=True)\n",
    "    pts_segids.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    temp = pts_segids['index_ln'].groupby(pts_segids['index_pt']).apply(list)\n",
    "    final = set([s[0] for s in temp if len(s)==1])\n",
    "    temp = [set(u)&set(v) for u,v in list(zip(temp,temp[1:]))]\n",
    "    final = final | set([list(s)[0] for s in temp if len(s)==1])\n",
    "    for idx,val in enumerate(temp):\n",
    "        if(len(val)>1 and len(val&final)==0): \n",
    "            final = final | val\n",
    "    total.append([idx,final])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mproc\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    def apply_fn(row):\n",
    "        \n",
    "        print(row.name)\n",
    "        lonlats = snap(row)\n",
    "        pts = [Point(lonlat) for lonlat in lonlats]\n",
    "        pts_gpdf = gpd.GeoDataFrame(pts, columns=['geometry'])\n",
    "\n",
    "        pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "\n",
    "        pts_segids = pts_segs_idx.merge(ph_str_gpd[['SEG_ID']], left_on=['index_ln'], right_index=True)\n",
    "        pts_segids.sort_values(by=['index_pt'],inplace=True)\n",
    "        pts_segids.reset_index(inplace=True,drop=True)\n",
    "\n",
    "        temp = pts_segids['index_ln'].groupby(pts_segids['index_pt']).apply(list)\n",
    "        final = set([s[0] for s in temp if len(s)==1])\n",
    "        temp = [set(u)&set(v) for u,v in list(zip(temp,temp[1:]))]\n",
    "        final = final | set([list(s)[0] for s in temp if len(s)==1])\n",
    "        for idx,val in enumerate(temp):\n",
    "            if(len(val)>1 and len(val&final)==0): \n",
    "                final = final | val\n",
    "        return pd.Series({'segments' : final})\n",
    "\n",
    "    def call_apply_fn(df):\n",
    "        return df.apply(apply_fn,axis=1)\n",
    "\n",
    "    new = pd.read_pickle('Data.pkl')\n",
    "    pool = mproc.Pool(mproc.cpu_count()) \n",
    "    results = pool.map(call_apply_fn, np.array_split(new,mproc.cpu_count()))\n",
    "    temp = pd.concat(results)\n",
    "    temp.to_pickle('Segments.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argmax(np.array([len(t.coords) for t in new.geometry]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snap_to_road import *\n",
    "row = new.ix[3899]\n",
    "pts = list(row.geometry.coords)\n",
    "samay = [(row.Start + k*(row.Stop-row.Start)/(len(pts)-1)).strftime('%H:%M:%S') for k in range(len(pts))]\n",
    "\n",
    "rang = list(zip(*pts))\n",
    "rang = [list(temp) for temp in rang]\n",
    "df = list(zip(samay,rang[0],rang[1]))\n",
    "df = pd.DataFrame(df,columns=['time','longitude','latitude'])\n",
    "service = mp.MapMatcher()\n",
    "print(len(pts))\n",
    "snap_to_road(service,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def apply_fn(row):\n",
    "    lonlats = list(row['geometry'].coords)\n",
    "    pts = [Point(lonlat) for lonlat in lonlats]\n",
    "    pts_gpdf = gpd.GeoDataFrame(pts, columns=['geometry'])\n",
    "    try:\n",
    "        pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    if(len(pts_no_segs)>0):\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "def call_apply_fn(df):\n",
    "    return df['geometry'].apply(apply_fn,axis=1)\n",
    "\n",
    "pool = Pool(4)\n",
    "pool_results = pool.map(call_apply_fn, np.array_split(purp.ix[0:9],mproc.cpu_count()))\n",
    "pool.close() \n",
    "pool.join() \n",
    "total = pd.concat(pool_results)\n",
    "total.to_pickle('Indices.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Output.txt','w') as f:\n",
    "    for item in pool_results:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flat(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traces = pd.read_pickle('Segments.pkl')\n",
    "traces.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = list(segments.segments[idx])\n",
    "t.append(35943)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map_plot(idx,flag1,seg,flag2):\n",
    "    if(flag1): lonlats = snap(new.iloc[idx])\n",
    "    else: lonlats = list(new.geometry[idx].coords)\n",
    "    pts = [Point(lonlat) for lonlat in lonlats]\n",
    "    start = 0\n",
    "    end = len(pts)\n",
    "    t = list(segments.segments[idx])\n",
    "    if(flag2): inpt = ph_str_gpd.iloc[t]\n",
    "    else: inpt = ph_str_gpd.iloc[seg]\n",
    "    otpt = pts[start:end+1]\n",
    "    gpdfs = [inpt, gpd.GeoDataFrame(otpt,columns=['geometry'])]\n",
    "    create_map_visualization(html_title, file_path, file_name, lat, lon, zoom, init_layers, map_layers, binding_data, gpdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lonlats[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = []\n",
    "for idx, row in purp.ix[0:4].iterrows():\n",
    "    lonlats = list(row['geometry'].coords)\n",
    "    pts = [Point(lonlat) for lonlat in lonlats]\n",
    "    pts_gpdf = gp.GeoDataFrame(pts, columns=['geometry'])\n",
    "    try:\n",
    "        pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "    except ValueError:\n",
    "        temp.append(0)\n",
    "        continue\n",
    "    if(len(pts_no_segs)>0):\n",
    "        temp.append(1)\n",
    "    else: temp.append(2)\n",
    "\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lonlats = list(purp[purp.TripID=='1377'].geometry.iloc[0].coords)\n",
    "pts = [Point(lonlat) for lonlat in lonlats]\n",
    "pts_gpdf = gp.GeoDataFrame(pts, columns=['geometry'])\n",
    "try:\n",
    "    pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "except ValueError:\n",
    "    print('HiHi')\n",
    "if(len(pts_no_segs)>=1):\n",
    "    print('HI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_writer(lonlats,'trip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts_segids[(pts_segids['index_pt']>=11)&(pts_segids['index_pt']<=15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt_idx = list(range(150,160))\n",
    "for ptx in pt_idx:\n",
    "    pt = pts_gpdf.geometry[ptx]\n",
    "\n",
    "    # the segments that are near pt 45\n",
    "    seg_indices = pts_segids[(pts_segids['index_pt']==ptx)].index_ln\n",
    "    print(\"Point Index: \"+str(ptx))\n",
    "    temp = ph_str_gpd.loc[seg_indices]['geometry'].index\n",
    "    temp2 = ph_str_gpd.loc[seg_indices]['geometry'].apply(lambda x: ptfromln(pt, x))\n",
    "    temp3 = ph_str_gpd.loc[seg_indices]['SEG_ID']\n",
    "    temp = sorted(list(zip(temp,temp3,temp2)),key=itemgetter(1))\n",
    "    for val in temp:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pt_idx = 15\n",
    "pt = pts_gpdf.geometry[pt_idx]\n",
    "\n",
    "# the segments that are near pt 45\n",
    "seg_indices = list(pts_segids[(pts_segids['index_pt']==pt_idx)].index_ln)\n",
    "seg_indices\n",
    "temp = ph_str_gpd.loc[seg_indices]['geometry'].index\n",
    "temp2 = ph_str_gpd.loc[seg_indices]['geometry'].apply(lambda x: ptfromln(pt, x))\n",
    "sorted(list(zip(temp,temp2)),key=itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the pt with index 45\n",
    "pt_idx = [44,45,46]\n",
    "for ptx in pt_idx:\n",
    "    pt = pts_gpdf.geometry[ptx]\n",
    "\n",
    "    # the segments that are near pt 45\n",
    "    seg_indices = pts_segids[(pts_segids['index_pt']==ptx)].index_ln\n",
    "    print(\"Point Index: \"+str(ptx))\n",
    "    temp = ph_str_gpd.loc[seg_indices]['geometry'].index\n",
    "    temp2 = ph_str_gpd.loc[seg_indices]['geometry'].apply(lambda x: ptfromln(pt, x))\n",
    "    temp3 = ph_str_gpd.loc[seg_indices]['SEG_ID']\n",
    "    temp = sorted(list(zip(temp,temp3,temp2)),key=itemgetter(1))\n",
    "    for val in temp:\n",
    "        print(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = len(pts)\n",
    "temp = pts_segids[(pts_segids['index_pt']>=start)&(pts_segids['index_pt']<=end)].index_ln\n",
    "# inpt = ph_str_gpd.iloc[temp]\n",
    "inpt = ph_str_gpd.iloc[final]\n",
    "otpt = pts[start:end+1]\n",
    "gpdfs = [inpt, gpd.GeoDataFrame(otpt,columns=['geometry'])]\n",
    "# gpdfs = [ph_str_gpd, gpd.GeoDataFrame(pts,columns=['geometry'])]\n",
    "create_map_visualization(html_title, file_path, file_name, lat, lon, zoom, init_layers, map_layers, binding_data, gpdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from leaflet_creation import create_map_visualization\n",
    "html_title = 'openstreetmap elements'\n",
    "file_path = ''\n",
    "file_name = 'test creation of leaflet'\n",
    "lon, lat = -75.17445310502671, 39.964070156312744  #D.C.\n",
    "zoom = 12\n",
    "init_layers = ['streets', 'stsg']\n",
    "map_layers = ['light','streets', 'satellite']\n",
    "binding_data=[['stsg','street segment'],['stsg1','street segment1']]\n",
    "ph_str_gpd['color'] = '#aa0'\n",
    "# gpdf2['color'] = '#0a0'\n",
    "# inpt = \n",
    "# otpt = pts[45:48]\n",
    "gpdfs = [ph_str_gpd, gpd.GeoDataFrame(pts,columns=['geometry'])]\n",
    "create_map_visualization(html_title, file_path, file_name, lat, lon, zoom, init_layers, map_layers, binding_data, gpdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_writer(new,filename):\n",
    "    with open(filename,'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Longitude\",\"Latitude\"])\n",
    "        writer.writerows(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crime = pd.read_csv('../phillydata/Crime_Details.csv')\n",
    "park = pd.read_csv('../phillydata/Philly_Parking_Violation_Details_2014-2015.csv')\n",
    "p311 = pd.read_csv('../phillydata/Philly_311_Details_2015-16.csv')\n",
    "cols = pd.read_csv('../phillydata/Philly_Collision_Details_2013-14.csv')\n",
    "bike = pd.read_csv('../phillydata/Philly_Bikelanes.csv')\n",
    "slope = pd.read_csv('../phillydata/Slope_Segment.csv')\n",
    "\n",
    "temp = crime.groupby(['STREETSEGID']).sum().reset_index()\n",
    "feat = temp[['STREETSEGID','CRIME_COUNT']]\n",
    "feat.columns = ['SEG_ID','CRIME']\n",
    "\n",
    "temp = park.groupby(['STREETSEGID']).sum().reset_index()\n",
    "feat2 = temp[['STREETSEGID','TYPE_COUNT']]\n",
    "feat2.columns = ['SEG_ID','PARKING']\n",
    "\n",
    "temp = p311.groupby(['SEG_ID']).sum().reset_index()\n",
    "feat3 = temp[['SEG_ID','monthly_311_request_count']]\n",
    "feat3.columns = ['SEG_ID','311_REQUEST']\n",
    "\n",
    "temp = cols.groupby(['SEG_ID']).sum().reset_index()\n",
    "feat4 = temp[['SEG_ID','TOTAL_COLLISION_COUNT']]\n",
    "feat4.columns = ['SEG_ID','COLLISION']\n",
    "\n",
    "slope.reset_index()\n",
    "\n",
    "feat5 = ph_str_gpd[['SEG_ID','SHAPE_LEN']]\n",
    "\n",
    "dfs = [feat,feat2,feat3,feat4,bike,slope,feat5]\n",
    "feat_final = reduce(lambda left,right: pd.merge(left,right,on='SEG_ID',how='outer'), dfs)\n",
    "feat_final.fillna(0,inplace=True)\n",
    "feat_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elev = pd.read_csv('../phillydata/Philly_Elevation_SegId.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elev = pd.read_csv('../phillydata/Philly_Elevation_SegId.csv')\n",
    "seg_id = sort(list(set(elev['SEG_ID'])))\n",
    "slope = []\n",
    "for seg in seg_id:\n",
    "    temp2 = elev[elev['SEG_ID']==seg].Elevation\n",
    "    temp3 = max(temp2)-min(temp2)\n",
    "    if argmax(temp2)<argmin(temp2):\n",
    "        temp3 = -temp3\n",
    "    slope.append(temp3)\n",
    "slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat6 = pd.DataFrame(list(zip(seg_id,slope)))\n",
    "feat6.columns = ['SEG_ID','ELEV_SLOPE']\n",
    "feat6.to_csv(\"../phillydata/Slope_Segment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buffer = set()\n",
    "final = set()\n",
    "temp = []\n",
    "for i in range(1,len(new)):\n",
    "    s1 = set(pts_segids[pts_segids['index_pt']==i-1].index_ln)\n",
    "    s2 = set(pts_segids[pts_segids['index_pt']==i].index_ln)\n",
    "    t = s1 & s2\n",
    "    temp.append(list(t))\n",
    "    if(len(t)==0):\n",
    "        continue\n",
    "    elif(len(t)==1):\n",
    "        final = final | t\n",
    "    else:\n",
    "        buffer = buffer | t\n",
    "        \n",
    "    if buffer:\n",
    "        tmp = buffer & t\n",
    "        if(len(tmp)==1):\n",
    "            final = final | tmp\n",
    "            buffer = set()\n",
    "#         else: print(i,len(tmp))\n",
    "#     if not t:\n",
    "#         t1 = ','.join(str(v) for v in s1)\n",
    "#         t2 = ','.join(str(v) for v in s2)\n",
    "#         print(str(i)+\" \"+t1+\"----\"+t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts_segids[(pts_segids['index_pt']>=115)&(pts_segids['index_pt']<=128)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unq_set = set()\n",
    "bfr = set()\n",
    "for i in range(0,50):#len(new)):\n",
    "    temp = set(pts_segids[pts_segids['index_pt']==i].index_ln)\n",
    "    t1 = ','.join(str(v) for v in temp)\n",
    "    t2 = ','.join(str(v) for v in bfr)\n",
    "    t3 = ','.join(str(v) for v in unq_set)\n",
    "    print(str(i)+\" Current: \"+t1+\" Buffer: \"+t2+\" Total: \"+t3)\n",
    "    if not bfr:\n",
    "        if not len(temp & unq_set):\n",
    "            bfr = bfr | temp\n",
    "        continue\n",
    "    if len(temp)==1:\n",
    "        unq_set = unq_set | temp\n",
    "        val = list(temp)[0]\n",
    "        if val in bfr:\n",
    "            bfr = set()\n",
    "            continue\n",
    "        else: \n",
    "            print(i)\n",
    "    bfr = bfr & temp\n",
    "    if not bfr:\n",
    "        print(\"P1 \"+str(i))\n",
    "    if len(bfr)==1:\n",
    "        val = list(bfr)[0]\n",
    "        if not val in unq_set:\n",
    "            print(\"P2\")\n",
    "            unq_set = unq_set | bfr\n",
    "        bfr = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(new)):\n",
    "    if not (unq_set & set(pts_segids[pts_segids['index_pt']==i].index_ln)):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pts_segids[(pts_segids['index_pt']>=13)&(pts_segids['index_pt']<=29)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = Counter(pts_segids.index_ln)\n",
    "sorted(x.items(), key=lambda pair: pair[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip = gpd.read_file('cyclephilly_rd2_geojson/cyclephilly_rd2_geojson.geojson')\n",
    "trip.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpta = gpd.read_file('trip_detail_rd2_shp/trip_detail_rd2.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mota.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(temp.Purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(temp.cycling_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip = gpd.read_file('nodes_geojson/CyclePhilly_Network_nodes.geojson')\n",
    "print(trip.shape)\n",
    "trip.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trip2 = gpd.read_file('nodes_shp/CyclePhilly_Network_nodes.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(trip.NO.isin([823213]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist = np.array([len(t.coords) for t in temp.geometry])\n",
    "print(len(hist[hist>30]))\n",
    "print(mean(hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(hist[hist>20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist2 = np.array([len(t.coords) for t in purp.geometry if t.type!=\"MultiLineString\"])\n",
    "print(len(hist2[hist2>30]))\n",
    "print(median(hist2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catg = list(sorted(set(purp.Purpose)))\n",
    "total_set = []\n",
    "for cat in catg:\n",
    "    subst = purp[purp.Purpose==cat]\n",
    "    temp = [list(temp.coords) for temp in subst.geometry]\n",
    "    temp = list(set(map(tuple, temp)))\n",
    "    temp = list(map(LineString,temp)) #subst[subst.geom_equals(t)].index[0]\n",
    "    unique_set = []\n",
    "    for t in temp:\n",
    "        for idx,tr in subst.iterrows():\n",
    "            if tr.geometry==t: \n",
    "                unique_set.append(idx)\n",
    "                break \n",
    "    total_set.extend(unique_set)\n",
    "    print(cat,len(set(total_set)),len(total_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_purp = purp.ix[total_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_purp.to_pickle('Route_Purpose.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purp = pd.read_pickle('Route_Purpose.pkl')\n",
    "print(purp.shape)\n",
    "purp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purp[purp.geom_equals(purp.geometry[515])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = purp.geometry[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = [datetime.strptime(temp, '%Y-%m-%dT%H:%M:%S')for temp in purp.Start]\n",
    "date = [temp.strftime(\"%Y/%m/%d\") for temp in start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = pd.DatetimeIndex(purp.Start)\n",
    "stop = pd.DatetimeIndex(purp.Stop)\n",
    "start = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purp['date'] = [temp.date() for temp in purp.Start]\n",
    "purp['month'] = [temp.month for temp in purp.Start]\n",
    "purp['hour'] = [temp.hour for temp in purp.Start]\n",
    "mon = list(range(1,13))\n",
    "temp = purp[purp.UserId!='4']\n",
    "count = [len(set(temp[temp.month==mn].UserId)) for mn in mon]\n",
    "\n",
    "rect = plt.bar(mon,count,bar_width)\n",
    "const = 20\n",
    "plt.title('Bikers/Month',fontsize=16)\n",
    "plt.ylabel('Number of Unique Bikers',fontsize=12)\n",
    "plt.xlabel('Month',fontsize=12)\n",
    "plt.yticks(np.arange(0,max(count)+2*const,const))\n",
    "plt.xticks(index + bar_width / 2, names)\n",
    "plt.xlim([0,14])\n",
    "autolabel(rect)\n",
    "savefig('Unique_Users_by_Month.jpg')\n",
    "# date = sorted(set(purp.date))\n",
    "# temp = purp[purp.UserId!='4']\n",
    "# count = [len(set(temp[temp.date==dt].UserId)) for dt in date]\n",
    "\n",
    "# temp = list(zip(*daily))\n",
    "# daily = temp[0]\n",
    "# count = temp[1]\n",
    "# list(zip(daily,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bike_month = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = list(range(24))\n",
    "temp = purp[purp.UserId!='4']\n",
    "count = [len(set(temp[temp.hour==nm].UserId)) for nm in names]\n",
    "\n",
    "index = np.arange(0,48,2)\n",
    "bar_width = 1\n",
    "fig,ax = plt.subplots()\n",
    "rect = ax.bar(index,count,bar_width)\n",
    "const = 20\n",
    "\n",
    "plt.title('Bikers/Hours',fontsize=16)\n",
    "plt.ylabel('Number of Unique Bikers',fontsize=12)\n",
    "plt.xlabel('Hours',fontsize=12)\n",
    "plt.yticks(np.arange(0,max(count)+2*const,const))\n",
    "ax.set_xticks(index+bar_width)\n",
    "ax.set_xlim(-2, 50)\n",
    "plt.xticks(index + bar_width / 2, names)\n",
    "autolabel(rect)\n",
    "savefig('Unique_Users_by_Hours.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2., height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "        \n",
    "month = [temp.month for temp in purp.Start]\n",
    "names = list(calendar.month_abbr)[1:]\n",
    "data = Counter(month)\n",
    "data = list(data.items())\n",
    "temp = list(zip(*data))\n",
    "mon = temp[0]\n",
    "count = temp[1]\n",
    "index = np.arange(12)\n",
    "bar_width = 0.9\n",
    "rect = plt.bar(index,count,bar_width)\n",
    "const = 200\n",
    "plt.title('Trips/Month',fontsize=16)\n",
    "plt.ylabel('Number of Trips',fontsize=12)\n",
    "plt.xlabel('Month',fontsize=12)\n",
    "plt.yticks(np.arange(0,max(count)+2*const,const))\n",
    "plt.xticks(index + bar_width / 2, names)\n",
    "plt.xlim([-1,13])\n",
    "autolabel(rect)\n",
    "# plt.show()\n",
    "savefig('Total_Trips_by_Month.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_month = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = np.array(trip_month)/np.array(bike_month)\n",
    "index = np.arange(12)\n",
    "bar_width = 0.9\n",
    "rect = plt.bar(index,count,bar_width)\n",
    "const = 2\n",
    "plt.title('Normalized_Trips/(Users,Month)',fontsize=16)\n",
    "plt.ylabel('Number of Trips',fontsize=12)\n",
    "plt.xlabel('Month',fontsize=12)\n",
    "plt.yticks(np.arange(0,max(count)+2*const,const))\n",
    "plt.xticks(index + bar_width / 2, names)\n",
    "plt.xlim([-1,13])\n",
    "autolabel(rect)\n",
    "savefig('Normalized_Trips_Users_Month.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = list(calendar.day_abbr)\n",
    "day = [names[temp.dayofweek] for temp in purp.Start]\n",
    "data = Counter(day)\n",
    "count = [data[t] for t in names]\n",
    "\n",
    "index = np.arange(7)\n",
    "bar_width = 0.9\n",
    "rect = plt.bar(index,count,bar_width)\n",
    "const = 200\n",
    "plt.title('Trips/Day',fontsize=16)\n",
    "plt.ylabel('Number of Trips',fontsize=12)\n",
    "plt.xlabel('Day',fontsize=12)\n",
    "plt.yticks(np.arange(0,max(count)+2*const,const))\n",
    "plt.xticks(index + bar_width / 2, names)\n",
    "autolabel(rect)\n",
    "plt.xlim([-1,8])\n",
    "# plt.show()\n",
    "savefig('Total_Trips_by_Day.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hour = [temp.hour for temp in purp.Start]\n",
    "data = Counter(hour)\n",
    "data = list(data.items())\n",
    "temp = list(zip(*data))\n",
    "mon = temp[0]\n",
    "count = temp[1]\n",
    "names = list(range(24))\n",
    "index = np.arange(0,48,2)\n",
    "bar_width = 1\n",
    "fig,ax = plt.subplots()\n",
    "rect = ax.bar(index,count,bar_width)\n",
    "const = 200\n",
    "\n",
    "plt.title('Trips/Hours',fontsize=16)\n",
    "plt.ylabel('Number of Trips',fontsize=12)\n",
    "plt.xlabel('Hours',fontsize=12)\n",
    "plt.yticks(np.arange(0,max(count)+2*const,const))\n",
    "ax.set_xticks(index+bar_width)\n",
    "ax.set_xlim(-2, 50)\n",
    "plt.xticks(index + bar_width / 2, names)\n",
    "autolabel(rect)\n",
    "# plt.show()\n",
    "savefig('Total_Trips_by_hours.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = purp.groupby(['age','gender','ethnicity','income']).size()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = list(counts.index)\n",
    "def f(x):\n",
    "    if not re.findall('no',x):\n",
    "        return True\n",
    "    return False\n",
    "temp = [t for t in temp if False not in list(map(f,t))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def life_saver(l):\n",
    "    print(\"\\n\".join([str(s) for s in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = gpd.read_file('cyclephilly_rd2_geojson/cyclephilly_rd2_geojson.geojson')\n",
    "temp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_bar(names,count,x,y):\n",
    "    index = np.arange(len(names))\n",
    "    bar_width = 0.9\n",
    "    plt.figure(1)\n",
    "    if(x=='Trips'):\n",
    "        no = 121        \n",
    "    else:\n",
    "        no = 122\n",
    "    \n",
    "    plt.subplot(no)\n",
    "    rect1 = plt.bar(index,count,bar_width)\n",
    "    const = int(max(count)*0.25)\n",
    "    plt.title(x+'/'+y,fontsize=14)\n",
    "    plt.ylabel('# of '+x,fontsize=12)\n",
    "    plt.xlabel(y,fontsize=12)\n",
    "    plt.yticks(np.arange(0,max(count)+2*const,const))\n",
    "    plt.xticks(index + bar_width / 2, names,rotation = 'vertical')\n",
    "    autolabel(rect1)\n",
    "    plt.xlim([-1,len(names)+1]);\n",
    "    plt.tight_layout()\n",
    "#     plt.setp(names)\n",
    "#     if(no==211): plt.show()\n",
    "    if(no==122):\n",
    "        plt.savefig(y+'.jpg')\n",
    "    \n",
    "\n",
    "name = 'ethnicity'\n",
    "data1 = Counter(purp[purp[name]!='no data'][name])\n",
    "names = list(data1.keys())\n",
    "count = list(data1.values())\n",
    "if(name=='income'):\n",
    "    names = [re.sub('999','',t) for t in names]\n",
    "    names = [re.sub('000','',t) for t in names]\n",
    "    names = [re.sub(',','',t) for t in names]\n",
    "    names[2],names[4] = names[4],names[2]\n",
    "    count[2],count[4] = count[4],count[2]\n",
    "elif(name=='age' or name=='ethnicity'):\n",
    "    t = list(zip(*sorted(data1.items(),key=lambda k: k[0])))\n",
    "    names = t[0]\n",
    "    count = t[1]\n",
    "\n",
    "plot_bar(names,count,'Trips',name.title())\n",
    "\n",
    "counts = purp.groupby(['UserId','age','gender','ethnicity','income']).size().reset_index()\n",
    "data2 = Counter(counts[counts[name]!='no data'][name])\n",
    "count = list(data2.values())\n",
    "if(name=='gender'):\n",
    "    names = list(data2.keys())\n",
    "elif(name=='ethnicity' or name=='age' ):\n",
    "    t = list(zip(*sorted(data2.items(),key=lambda k: k[0])))\n",
    "    names = t[0]\n",
    "    count = t[1]\n",
    "plot_bar(names,count,'Users',name.title())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments = pd.read_pickle('Segments.pkl')\n",
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(unique([item for l in unique(segments.segments) for item in l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Yearly Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter([t.year for t in new.Start])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### POI's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poi = pd.read_csv('feature_poi_ph.csv',index_col=0)\n",
    "poi.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments = pd.read_pickle('Segments.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_fn(row):\n",
    "    t = list(row.coords)\n",
    "    pts = [Point(lonlat) for lonlat in [t[0],t[1],t[-2],t[-1]]]\n",
    "    pts_gpdf = gpd.GeoDataFrame(pts, columns=['geometry'])\n",
    "    pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "\n",
    "    pts_segids = pts_segs_idx.merge(ph_str_gpd[['SEG_ID']], left_on=['index_ln'], right_index=True)\n",
    "    pts_segids.sort_values(by=['index_pt'],inplace=True)\n",
    "    pts_segids.reset_index(inplace=True,drop=True)\n",
    "    pts_segids.T\n",
    "\n",
    "    t1 = set(pts_segids.index_ln[pts_segids.index_pt==0]) & set(pts_segids.index_ln[pts_segids.index_pt==1])\n",
    "    t2 = set(pts_segids.index_ln[pts_segids.index_pt==2]) & set(pts_segids.index_ln[pts_segids.index_pt==3])\n",
    "    return pd.Series({'start':t1,'end':t2})\n",
    "\n",
    "\n",
    "def call_apply_fn(df):\n",
    "    return df.apply(apply_fn)\n",
    "\n",
    "pool = mproc.Pool(mproc.cpu_count()) \n",
    "results = pool.map(call_apply_fn, np.array_split(new.geometry.ix[0:10],mproc.cpu_count()))\n",
    "temp = pd.concat(results)\n",
    "temp\n",
    "# apply_fn(new.geometry[146])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upoi = pd.read_pickle('Updated_POI.pkl')\n",
    "upoi.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = np.array([len(row['end'])+len(row['start']) for idx,row in upoi.iterrows()])\n",
    "len(upoi.ix[np.where(t>2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(new.geom_equals(purp.geometry[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = upoi['start'].apply(lambda x: poi.ix[list(x)].mean(axis=0).round())\n",
    "temp.fillna(0,inplace=True)\n",
    "temp.drop('total', axis=1)\n",
    "feat1 = temp.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = upoi['start'].apply(lambda x: poi.ix[list(x)].mean(axis=0).round())\n",
    "temp.fillna(0,inplace=True)\n",
    "temp.drop('total', axis=1, inplace=True)\n",
    "feat1 = temp.as_matrix()\n",
    "\n",
    "temp = upoi['end'].apply(lambda x: poi.ix[list(x)].mean(axis=0).round())\n",
    "temp.fillna(0,inplace=True)\n",
    "temp.drop('total', axis=1, inplace=True)\n",
    "feat2 = temp.as_matrix()\n",
    "\n",
    "# temp = pd.concat([new.Start.dt.hour, new.Start.dt.month, new.Start.dt.dayofweek],axis=1)\n",
    "# feat3 = temp.as_matrix()\n",
    "    \n",
    "feat1.shape, feat2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat1 = feat1[purp['seg']]\n",
    "feat2 = feat2[purp['seg']]\n",
    "data = pd.concat([purp.Start.dt.hour,purp.Start.dt.month,purp.Start.dt.dayofweek],axis=1)\n",
    "feat3 = data.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat([purp.Purpose,purp.Start.dt.hour],axis=1)\n",
    "sns.boxplot(x=\"Purpose\",y=\"Start\",data=data)\n",
    "plt.title('Hour',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = list(calendar.month_abbr)\n",
    "data = pd.concat([purp.Purpose,purp.Start.dt.month],axis=1)\n",
    "sns.boxplot(x=\"Purpose\",y=\"Start\",data=data)\n",
    "plt.yticks(plt.yticks()[0],labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = list(calendar.day_abbr)\n",
    "data = pd.concat([purp.Start.dt.dayofweek,purp.Purpose],axis=1)\n",
    "sns.boxplot(x=\"Purpose\",y=\"Start\",data=data)\n",
    "plt.yticks(plt.yticks()[0],labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_fn(row):\n",
    "        \n",
    "    t = list(row.geometry.coords)\n",
    "    lonlats = snap(row)\n",
    "    pts = [Point(lonlat) for lonlat in [lonlats[0],lonlats[-1]]]\n",
    "    pts_gpdf = gpd.GeoDataFrame(pts, columns=['geometry'])\n",
    "    pts_segs_idx, pts_no_segs = pts2segs(pts_gpdf, ph_str_gpd, bfr_crs=3559, init_crs=4326, close_jn_dist=10, far_jn_dist=30)\n",
    "\n",
    "    pts_segids = pts_segs_idx.merge(ph_str_gpd[['SEG_ID']], left_on=['index_ln'], right_index=True)\n",
    "    pts_segids.sort_values(by=['index_pt'],inplace=True)\n",
    "    pts_segids.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    t1 = set(pts_segids.index_ln[pts_segids.index_pt==0]) & segments.segments[row.name]\n",
    "    t2 = set(pts_segids.index_ln[pts_segids.index_pt==1]) & segments.segments[row.name]\n",
    "    return pd.Series({'start':t1,'end':t2})\n",
    "    \n",
    "def call_apply_fn(df):\n",
    "    return df.apply(apply_fn,axis=1)\n",
    "\n",
    "pool = mproc.Pool(mproc.cpu_count()) \n",
    "results = pool.map(call_apply_fn, np.array_split(new.ix[0:10],mproc.cpu_count()))\n",
    "temp = pd.concat(results)\n",
    "# temp.to_pickle('Updated_POI.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import radviz\n",
    "radviz(data,'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = np.concatenate((feat1,feat2,feat3),axis=1)\n",
    "# np.save('Training_Feature.npy',X)\n",
    "np.linspace(10, 100, num=10,dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier with just time as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.concat([purp.Start.dt.hour,purp.Start.dt.month,purp.Start.dt.dayofweek,purp.Purpose],axis=1)\n",
    "data.columns = ['Hour','Month','Day','Label']\n",
    "data.head()\n",
    "\n",
    "data['Label'] = data['Label'].astype('category')\n",
    "labels = dict( enumerate(data.Label.cat.categories) )\n",
    "data['Label'] = data['Label'].cat.codes\n",
    "\n",
    "X = np.array(data.ix[:, data.columns != 'Label'])\n",
    "y = np.array(data.Label)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "clf = SVC(kernel='rbf', gamma = 0.9, C=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier with POI and Time as classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = [\"start\"+\"_\"+col for col in poi.columns.tolist()[:-1]]\n",
    "f2 = [\"end\"+\"_\"+col for col in poi.columns.tolist()[:-1]]\n",
    "cols = f1+f2+['month','time','day']\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = np.load('Training_Feature.npy')\n",
    "temp = purp.Purpose.astype('category')\n",
    "labels = dict( enumerate(temp.cat.categories))\n",
    "y = np.array(temp.cat.codes)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3)\n",
    "    \n",
    "clf = SVC(kernel='rbf', gamma = 0.05, C=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred, target_names=list(labels.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = np.load('Training_Feature.npy')\n",
    "temp = purp.Purpose.astype('category')\n",
    "labels = dict( enumerate(temp.cat.categories) )\n",
    "y = np.array(temp.cat.codes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3)\n",
    "\n",
    "clf = SVC(kernel='rbf', gamma = 0.01, C=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred, target_names=list(labels.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# X = np.load('Training_Feature.npy')\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=50)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred, target_names=list(labels.values())))\n",
    "\n",
    "sorted(list(zip(cols,clf.feature_importances_)),key = lambda w: w[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = np.load('Training_Feature.npy')\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred, target_names=list(labels.values())))\n",
    "# sorted(list(zip(cols,clf.feature_importances_)),key = lambda w: w[1],reverse=True)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Counter(purp.Purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=0)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=500,max_depth=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred, target_names=list(labels.values())))\n",
    "# sorted(list(zip(cols,clf.feature_importances_)),key = lambda w: w[1],reverse=True)\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 2e-3],\n",
    "                     'C': [10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(C=10), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crash = pickle.load(open('data/Collision_Stats.pkl','rb'))\n",
    "crime = pickle.load(open('data/Crime_Stats.pkl','rb'))\n",
    "park = pickle.load(open('data/Park_Stats.pkl','rb'))\n",
    "three11 = pickle.load(open('data/311_Requested_Date_Stats.pkl','rb'))\n",
    "bike = pd.read_csv('../phillydata/Philly_Bikelanes.csv',index_col=0)\n",
    "slope = pd.read_csv('../phillydata/Slope_Segment.csv',index_col=0)\n",
    "\n",
    "\n",
    "traces = pd.read_pickle('Segments.pkl').segments\n",
    "traces = traces.apply(lambda x: [ph_str_gpd.SEG_ID[t] for t in x])\n",
    "segments = set().union(*traces)\n",
    "\n",
    "inpt = ['crash','crime','park','three11']\n",
    "final = []\n",
    "for i in inpt:\n",
    "    data = eval(i)\n",
    "    temp = list(zip(*data.keys()))\n",
    "    temp = pd.DataFrame(list(zip(temp[0],temp[1],data.values())),columns=['seg','month','value'])\n",
    "    temp = temp.pivot(index='seg',columns='month',values='value')\n",
    "    temp = temp[temp.index.isin(segments)]\n",
    "    temp = temp[temp.columns[(temp.columns>='2014-05') & (temp.columns<='2016-04')]].to_sparse()\n",
    "    missing = list(segments-set(temp.index))\n",
    "    temp = temp.loc[temp.index.tolist() + missing]\n",
    "    temp.columns = [i+\"_\"+col for col in temp.columns]\n",
    "    final.append(temp)\n",
    "feature = pd.concat(final,axis=1)\n",
    "feature['bike_lane'] = bike.loc[feature.index.tolist()].BIKELANE\n",
    "feature['slope'] = slope.loc[feature.index.tolist()].ELEV_SLOPE\n",
    "feature = feature.to_sparse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature.to_pickle('Complete_Training_Feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = pd.read_pickle('Complete_Training_Feature.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix,vstack\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "feature = pd.read_pickle('Complete_Training_Feature.pkl')\n",
    "X = np.load('Training_Feature.npy')\n",
    "traces = pd.read_pickle('Segments.pkl').segments\n",
    "traces = traces.apply(lambda x: [ph_str_gpd.SEG_ID[t] for t in x])\n",
    "inpt = ['crash','crime','park','three11']\n",
    "\n",
    "flag = True\n",
    "for idx,row in purp.ix[:99].iterrows():\n",
    "    f = [i+\"_\"+row.Start.strftime(\"%Y-%m\") for i in inpt]\n",
    "    f = f + ['bike_lane','slope']\n",
    "\n",
    "    t = feature.loc[traces[row.seg],f]\n",
    "    t = t.reindex(index=feature.index,columns=feature.columns)\n",
    "    t.fillna(0,inplace=True)\n",
    "    \n",
    "    temp = csr_matrix(np.append(t.values.ravel(),X[idx]))\n",
    "    \n",
    "    if(flag): \n",
    "        flag = False\n",
    "        feat = temp\n",
    "    else: feat = vstack([feat,temp])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MaxAbsScaler().fit_transform(feature.slope.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MaxAbsScaler().fit_transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "svd.fit(feat) \n",
    "\n",
    "\n",
    "print(svd.explained_variance_ratio_) \n",
    "\n",
    "print(svd.explained_variance_ratio_.sum()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(kernel='rbf',gamma=0.01, C=10),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "X = np.load('Training_Feature.npy')\n",
    "temp = purp.Purpose.astype('category')\n",
    "labels = dict( enumerate(temp.cat.categories))\n",
    "y = np.array(temp.cat.codes)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(name,score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = load_npz('Sparse_Matrix.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fc686f2dda19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfeat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Train_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "f = open('Final_Report.txt','w')\n",
    "\n",
    "test = [10,20,30,40]\n",
    "\n",
    "for val in test: \n",
    "    svd = TruncatedSVD(n_components=val)\n",
    "    feat2 = svd.fit_transform(feat)\n",
    "    if(val==40):\n",
    "        print(8/0)\n",
    "    name = 'Train_'+str(val)+'.npy'\n",
    "    np.save(name,feat2)\n",
    "    print(\"Dimension: \"+str(val)+\" Explained variance ratio: \"+str(svd.explained_variance_ratio_.sum())+\"\\n\",file=f)\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
